# External imports
import argparse
import json
import numpy as np
from tensorflow.keras.callbacks import ModelCheckpoint
from music21 import converter, note, chord, instrument, stream

# Internal imports
import data
import models
import gan


# Constants
MODEL_LIST = ['LSTM', 'transformer', 'GAN']
DATA_MODES = ['Numeric']

if __name__ == "__main__":
    # Initialize argparse
    parser = argparse.ArgumentParser()

    # General arguments
    parser.add_argument('-m', '--model_type', help=f'Model Type', choices=MODEL_LIST, required=True)
    parser.add_argument('-b', '--batch_size', help='Batch size', type=int, default=64)
    parser.add_argument('-d', '--data_mode', help=f'How to encode the MIDI data', choices=DATA_MODES, default='Numeric')
    parser.add_argument('-s', '--seq_len', help='Length of input sequence to model', type=int, default=50)
    parser.add_argument('-p', '--data_path', help='Path to training data', default='./data/val.pkl')
    parser.add_argument('-w', '--weights_path', help='Path to model weights', default='./weights/')
    parser.add_argument('-a', '--hparam_path', help='Path to model hyperparams', default='./weights/')
    parser.add_argument('-i', '--num_iterations', help='Number of iterations to run', type=int, default=500)

    # Parse arguments
    args = parser.parse_args()

    # Initialize dataset
    if args.data_mode == 'Numeric':
        dataset = data.MIDINumericDataset(path=args.data_path, sequence_len=args.seq_len)
        out_shape = 1
        int_to_note = dict((number, note) for number, note in enumerate(dataset.pitchnames))


    # Load model hyperparameters
    with open(args.hparam_path, 'r') as f:
        model_hparams = json.load(f)


    # Create model
    model, *_ = models.load_from_dict(model_hparams)

    with open('hi3.txt', 'w') as f:
        f.write('bye')

    # Load weights
    filepath = args.weights_path
    model.load_weights(filepath)


    if args.model_type != 'GAN':


        # Preprocess data
        network_input, network_output = dataset.get_data()

        # Choose a starting point
        start = np.random.randint(0, len(network_input)-1)

        pattern = network_input[start]

        prediction_output = []

        nNotes = 500 # about 2 min
        # generate notes
        for note_index in range(nNotes):
            # Prepare prediction inputs
            prediction_input = np.reshape(pattern, (1, len(pattern), 1))
            prediction_input = prediction_input / float(dataset.n_vocab)

            # Get prediction
            prediction = model.predict(prediction_input, verbose=0)

            # Randomly sample from prediction vector
            p = prediction.squeeze()
            print(f'Prediction: {prediction.shape}')
            print(f'p: {p.shape}')
            print(f'n_vocab: {dataset.n_vocab}')
            index = int(np.random.choice(dataset.n_vocab, 1, p=p/p.sum()))

            # Convert prediction to note
            result = int_to_note[index]
            prediction_output.append(result)
            pattern = np.append(pattern, index)
            pattern = pattern[1:len(pattern)]

    else:
        print('Generating note')
        notes,_ = gan.generate_fake_samples(model, model_hparams['latent_dim'], args.num_iterations)
        predictions = np.reshape(notes, (-1, notes.shape[-2]))
        prediction_output = []

        for prediction in predictions:
            if prediction.sum() == 0:
                prediction += 1
            index = int(np.random.choice(dataset.n_vocab, 1, p=prediction/prediction.sum()))

            # Convert prediction to note
            result = int_to_note[index]
            prediction_output.append(result)
        

    # turn predictions into notes

    offset = 0
    output_notes = []
    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
        # increase offset each iteration so that notes do not stack
        offset += 0.5

    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='test_output.mid')

